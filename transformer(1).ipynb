{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3531703,"sourceType":"datasetVersion","datasetId":2123951},{"sourceId":5094410,"sourceType":"datasetVersion","datasetId":2958426},{"sourceId":8856029,"sourceType":"datasetVersion","datasetId":5331126}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model,Sequential,load_model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport csv\nimport os\nfrom IPython.display import clear_output\nimport re\nimport unicodedata","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:17:50.525059Z","iopub.execute_input":"2024-08-31T07:17:50.525804Z","iopub.status.idle":"2024-08-31T07:17:54.316729Z","shell.execute_reply.started":"2024-08-31T07:17:50.525770Z","shell.execute_reply":"2024-08-31T07:17:54.315912Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-31 07:17:50.897445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-31 07:17:50.897518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-31 07:17:50.899228: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:29:25.769253Z","iopub.execute_input":"2024-08-31T07:29:25.770345Z","iopub.status.idle":"2024-08-31T07:29:25.777251Z","shell.execute_reply.started":"2024-08-31T07:29:25.770312Z","shell.execute_reply":"2024-08-31T07:29:25.776343Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.15.0'"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Si se va a usar tpu\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converts the unicode file to ascii\ndef unicode_to_ascii(s):\n    return ''.join(c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn')\n\n\ndef preprocess_sentence(w):\n    w = unicode_to_ascii(w.lower().strip())\n\n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n    w = re.sub(r'[\" \"]+', \" \", w)\n\n    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n    w = re.sub(r\"[^a-zA-Z?.!,¿0-9]+\", \" \", w)\n\n    w = w.strip()\n\n    # adding a start and an end token to the sentence\n    # so that the model know when to start and stop predicting.\n    return w","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:29:46.852409Z","iopub.execute_input":"2024-08-31T07:29:46.852781Z","iopub.status.idle":"2024-08-31T07:29:46.859975Z","shell.execute_reply.started":"2024-08-31T07:29:46.852754Z","shell.execute_reply":"2024-08-31T07:29:46.858966Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"file = open(\"/kaggle/input/bbc-news-articles/bbc_news_20220307_20240703.csv\",\"r\")\nreader = csv.reader(file)\nentrada_texto = []\nsalida_texto = []\nist_first = True\nfor row in reader:\n    if ist_first:\n        ist_first = False\n        continue\n    entrada_texto.append(row[0])\n    salida_texto.append(row[4])\n    \n\nsize = None\nbegin_token = \"<sos>\"\nend_token = \"<eos>\"\n\n\nentrada_texto_p = [\n    \"{} {} {}\".format(\n        begin_token,\n        preprocess_sentence(text.lower()),\n        end_token) for text in entrada_texto[:size]]\nsalida_texto_p = [\n    \"{} {} {}\".format(\n        begin_token,\n        preprocess_sentence(text.lower()),\n        end_token) for text in salida_texto[:size]]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:14.115974Z","iopub.execute_input":"2024-08-31T07:31:14.116716Z","iopub.status.idle":"2024-08-31T07:31:17.845305Z","shell.execute_reply.started":"2024-08-31T07:31:14.116684Z","shell.execute_reply":"2024-08-31T07:31:17.844236Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(entrada_texto_p[0])\nprint(\"-\"*20)\nprint(salida_texto_p[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:17.847025Z","iopub.execute_input":"2024-08-31T07:31:17.847352Z","iopub.status.idle":"2024-08-31T07:31:17.851922Z","shell.execute_reply.started":"2024-08-31T07:31:17.847320Z","shell.execute_reply":"2024-08-31T07:31:17.851019Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<sos> ukraine angry zelensky vows to punish russian atrocities <eos>\n--------------------\n<sos> the ukrainian president says the country will not forgive or forget those who murder its civilians . <eos>\n","output_type":"stream"}]},{"cell_type":"code","source":"## Parámetros para el tokenizador\nmax_len = 100\nfilters = '!\"#$%&()*+-/:?@[\\\\]^_`{|}~\\t¡’’'\n\ntokenizer = Tokenizer(num_words=None, oov_token='<OOV>',filters=filters)\ntokenizer.fit_on_texts(entrada_texto_p,)\ntokenizer.fit_on_texts(salida_texto_p)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:27.274097Z","iopub.execute_input":"2024-08-31T07:31:27.274990Z","iopub.status.idle":"2024-08-31T07:31:28.963877Z","shell.execute_reply.started":"2024-08-31T07:31:27.274957Z","shell.execute_reply":"2024-08-31T07:31:28.963055Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Este codigo es si vas a cargar checkpoints\nimport json\nfrom tensorflow.keras.preprocessing.text import tokenizer_from_json\nf1 = open(\"tokenizer.json\")\nmax_len = 600\nfilters = '!\"#$%&()*+-/:?@[\\\\]^_`{|}~\\t¡’’'\njson1 = json.load(f1)\ntokenizer = tokenizer_from_json(json1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size=len(tokenizer.word_index)\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:33.932014Z","iopub.execute_input":"2024-08-31T07:31:33.932619Z","iopub.status.idle":"2024-08-31T07:31:33.937869Z","shell.execute_reply.started":"2024-08-31T07:31:33.932579Z","shell.execute_reply":"2024-08-31T07:31:33.936822Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"34019\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences_input = tokenizer.texts_to_sequences(entrada_texto_p)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:36.429752Z","iopub.execute_input":"2024-08-31T07:31:36.430119Z","iopub.status.idle":"2024-08-31T07:31:36.974237Z","shell.execute_reply.started":"2024-08-31T07:31:36.430091Z","shell.execute_reply":"2024-08-31T07:31:36.973334Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"padded_input = pad_sequences(sequences_input)\nsequences_output = tokenizer.texts_to_sequences(salida_texto_p)\npadded_output = pad_sequences(sequences_output,maxlen=max_len+1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:37.069753Z","iopub.execute_input":"2024-08-31T07:31:37.070073Z","iopub.status.idle":"2024-08-31T07:31:38.123880Z","shell.execute_reply.started":"2024-08-31T07:31:37.070050Z","shell.execute_reply":"2024-08-31T07:31:38.122824Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(len(padded_input))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:40.046633Z","iopub.execute_input":"2024-08-31T07:31:40.047377Z","iopub.status.idle":"2024-08-31T07:31:40.051916Z","shell.execute_reply.started":"2024-08-31T07:31:40.047346Z","shell.execute_reply":"2024-08-31T07:31:40.050899Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"35860\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=16\n# Crear un objeto Dataset a partir de los datos tokenizados\ndataset = tf.data.Dataset.from_tensor_slices((padded_input, padded_output))\ndataset = dataset.batch(batch_size).shuffle(1024)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:42.627113Z","iopub.execute_input":"2024-08-31T07:31:42.627496Z","iopub.status.idle":"2024-08-31T07:31:43.108346Z","shell.execute_reply.started":"2024-08-31T07:31:42.627464Z","shell.execute_reply":"2024-08-31T07:31:43.107562Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for x,y in dataset.take(1):\n    print(x.shape,y.shape)\n    x0,y0 = np.array([x[0]]).tolist(),np.array([y[0]]).tolist()\n    print(x0,y0)\n    print(tokenizer.sequences_to_texts(x0),tokenizer.sequences_to_texts(y0))\n    \nprint(len(tokenizer.word_index))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:31:45.173677Z","iopub.execute_input":"2024-08-31T07:31:45.174401Z","iopub.status.idle":"2024-08-31T07:31:45.241703Z","shell.execute_reply.started":"2024-08-31T07:31:45.174366Z","shell.execute_reply":"2024-08-31T07:31:45.240788Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(16, 28) (16, 101)\n[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 864, 89, 87, 168, 400, 174, 343, 6, 343, 7, 251, 606, 3]] [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1408, 22, 331, 210, 11, 147, 1108, 643, 26, 606, 406, 14, 4, 42, 14, 563, 5, 3]]\n['<OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <sos> ni election 2022 party leaders go head to head in tv debate <eos>'] ['<OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <sos> politicians from northern ireland s five largest parties will debate live on the bbc on tuesday . <eos>']\n34019\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_look_ahead_mask(size):\n    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    return mask  # (seq_len, seq_len)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:02.760381Z","iopub.execute_input":"2024-08-31T07:32:02.761119Z","iopub.status.idle":"2024-08-31T07:32:02.765710Z","shell.execute_reply.started":"2024-08-31T07:32:02.761089Z","shell.execute_reply":"2024-08-31T07:32:02.764669Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def scaled_dot_product_attention(q, k, v, mask):\n  \n    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n\n    # scale matmul_qk\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    # add the mask to the scaled tensor.\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)\n\n    # softmax is normalized on the last axis (seq_len_k) so that the scores\n    # add up to 1.\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n\n    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n\n    return output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:03.272053Z","iopub.execute_input":"2024-08-31T07:32:03.272543Z","iopub.status.idle":"2024-08-31T07:32:03.279483Z","shell.execute_reply.started":"2024-08-31T07:32:03.272510Z","shell.execute_reply":"2024-08-31T07:32:03.278457Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass SelfMultiHeadAttention(tf.keras.layers.Layer):\n    def __init__(self, num_heads , d_model, dropout_rate):\n        super(SelfMultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n        self.depth = d_model // self.num_heads\n\n        self.wq = Dense(d_model)\n        self.wk = Dense(d_model)\n        self.wv = Dense(d_model)\n\n        self.dense = Dense(d_model)\n        self.drop = Dropout(dropout_rate)\n        self.drop1 = Dropout(dropout_rate)\n        self.drop2 = Dropout(dropout_rate)\n        self.drop3 = Dropout(dropout_rate)\n        \n    def split_heads(self, x, batch_size):\n        \"\"\"Split the last dimension into (num_heads, depth).\n        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n        \"\"\"\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n\n    def call(self, v, k, q, attention_mask):\n        batch_size = tf.shape(q)[0]\n\n        q = self.drop1(self.wq(q))  # (batch_size, seq_len, d_model)\n        k = self.drop2(self.wk(k))  # (batch_size, seq_len, d_model)\n        v = self.drop3(self.wv(v))  # (batch_size, seq_len, d_model)\n\n        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n\n        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, attention_mask)\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n\n        concat_attention = tf.reshape(scaled_attention,\n                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n        \n        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n        output = self.drop(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:03.942851Z","iopub.execute_input":"2024-08-31T07:32:03.943772Z","iopub.status.idle":"2024-08-31T07:32:03.955670Z","shell.execute_reply.started":"2024-08-31T07:32:03.943728Z","shell.execute_reply":"2024-08-31T07:32:03.954803Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass FeedForward(Layer):\n    def __init__(self, d_model, dff, dropout_rate=0.1):\n        super().__init__()\n        self.seq = tf.keras.Sequential([\n        tf.keras.layers.Dense(dff, activation='relu'),\n        tf.keras.layers.Dense(d_model),\n        tf.keras.layers.Dropout(dropout_rate)\n        ])\n        self.add = tf.keras.layers.Add()\n        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, x):\n        x = self.add([x, self.seq(x)])\n        x = self.layer_norm(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:04.605176Z","iopub.execute_input":"2024-08-31T07:32:04.605543Z","iopub.status.idle":"2024-08-31T07:32:04.612659Z","shell.execute_reply.started":"2024-08-31T07:32:04.605518Z","shell.execute_reply":"2024-08-31T07:32:04.611725Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def get_angles(pos, i, d_model):\n    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n    return pos * angle_rates","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:05.653606Z","iopub.execute_input":"2024-08-31T07:32:05.654576Z","iopub.status.idle":"2024-08-31T07:32:05.660097Z","shell.execute_reply.started":"2024-08-31T07:32:05.654530Z","shell.execute_reply":"2024-08-31T07:32:05.659048Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def positional_encoding(position, d_model):\n    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n                          np.arange(d_model)[np.newaxis, :],\n                          d_model)\n\n    # apply sin to even indices in the array; 2i\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n\n    # apply cos to odd indices in the array; 2i+1\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:06.589231Z","iopub.execute_input":"2024-08-31T07:32:06.590090Z","iopub.status.idle":"2024-08-31T07:32:06.596055Z","shell.execute_reply.started":"2024-08-31T07:32:06.590055Z","shell.execute_reply":"2024-08-31T07:32:06.595074Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass EncoderLayer(tf.keras.Layer):\n    def __init__(self,dim,n_heads,dff,dropout_rate=0.1):\n        super(EncoderLayer,self).__init__()\n        self.mha = SelfMultiHeadAttention(n_heads,dim,dropout_rate=dropout_rate)\n        self.ffn = FeedForward(dim,dff,dropout_rate)\n        self.norm1 = LayerNormalization(epsilon=1e-6)\n        self.norm2 = LayerNormalization(epsilon=1e-6)\n    def build(self, input_shape):\n        super(EncoderLayer, self).build(input_shape)\n\n    def call(self,x,training=True,src_padding_mask=None):\n        out1 = self.mha(x,x,x,attention_mask=src_padding_mask,training=training)\n        out1 = self.norm1(out1+x)\n        out2 = self.ffn(out1)\n        out2 = self.norm2(out1+out2)\n        return out2","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:07.561828Z","iopub.execute_input":"2024-08-31T07:32:07.562206Z","iopub.status.idle":"2024-08-31T07:32:07.570244Z","shell.execute_reply.started":"2024-08-31T07:32:07.562176Z","shell.execute_reply":"2024-08-31T07:32:07.569172Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass DecoderLayer(tf.keras.Layer):\n    def __init__(self,dim,n_heads,dff,dropout_rate=0.1):\n        super(DecoderLayer,self).__init__()\n        self.mha1 = SelfMultiHeadAttention(n_heads,dim,dropout_rate=dropout_rate)\n        self.mha2 = SelfMultiHeadAttention(n_heads,dim,dropout_rate=dropout_rate)\n        self.norm1 = LayerNormalization(epsilon=1e-6)\n        self.norm2 = LayerNormalization(epsilon=1e-6)\n        self.norm3 = LayerNormalization(epsilon=1e-6)\n        self.ffn = FeedForward(dim,dff,dropout_rate)\n    def build(self, input_shape):\n        super(DecoderLayer, self).build(input_shape)\n\n    def call(self,x,enc_output,look_ahead_mask=None,padding_mask=None):\n        out1 = self.mha1(x,x,x,attention_mask=look_ahead_mask)\n        out1 = self.norm1(x+out1)\n        out2 = self.mha2(enc_output,enc_output,out1,attention_mask=padding_mask)\n        out2 = self.norm2(out1+out2)\n        out3 = self.ffn(out2)\n        out3 = self.norm3(out3+out2)\n        return out3","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:08.403782Z","iopub.execute_input":"2024-08-31T07:32:08.404148Z","iopub.status.idle":"2024-08-31T07:32:08.413140Z","shell.execute_reply.started":"2024-08-31T07:32:08.404119Z","shell.execute_reply":"2024-08-31T07:32:08.411992Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass Encoder(tf.keras.Layer):\n    def __init__(self,dim,n_layers,n_heads,dff,vocab_size,dropout_rate=0.1,length=2048):\n        super(Encoder,self).__init__()\n        self.n_layers = n_layers\n        self.dim = dim\n        self.embedding = Embedding(vocab_size,dim)\n        self.enc_layers = [\n            EncoderLayer(dim,n_heads,dff,dropout_rate) for _ in range(n_layers)\n        ]\n        self.drop=Dropout(dropout_rate)\n        self.pos_encoding = positional_encoding(length,\n            self.dim)\n        self.dropout=Dropout(dropout_rate)\n    def build(self, input_shape):\n        super(Encoder, self).build(input_shape)\n\n    def call(self,x,src_padding_mask=None,training=None):\n        seq_len = tf.shape(x)[1]\n\n        # adding embedding and position encoding.\n        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n        x *= tf.math.sqrt(tf.cast(self.dim, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n\n        for i in range(self.n_layers):\n            x = self.enc_layers[i](x,src_padding_mask=src_padding_mask)\n        x = self.drop(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:09.369539Z","iopub.execute_input":"2024-08-31T07:32:09.370391Z","iopub.status.idle":"2024-08-31T07:32:09.380111Z","shell.execute_reply.started":"2024-08-31T07:32:09.370356Z","shell.execute_reply":"2024-08-31T07:32:09.379173Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass Decoder(tf.keras.Layer):\n    def __init__(self,dim,n_layers,n_heads,dff,vocab_size,dropout_rate=0.1,length=2048):\n        super(Decoder,self).__init__()\n        self.n_layers = n_layers\n        self.dim = dim\n        self.embedding = tf.keras.layers.Embedding(vocab_size, dim)\n        self.pos_encoding = positional_encoding(length, dim)\n        self.dec_layers = [\n            DecoderLayer(dim,n_heads,dff,dropout_rate) for _ in range(n_layers)\n        ]\n        self.dropout = Dropout(dropout_rate)\n    def build(self, input_shape):\n        super(Decoder, self).build(input_shape)\n\n    def call(self,x,enc_out,look_ahead_mask=None,tgt_padding_mask=None,training=None):\n        seq_len = tf.shape(x)[1]\n        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n        x *= tf.math.sqrt(tf.cast(self.dim, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n        x = self.dropout(x,training=training)\n        for i in range(self.n_layers):\n            x = self.dec_layers[i](\n                x,\n                enc_out,\n                look_ahead_mask=look_ahead_mask,\n                padding_mask=tgt_padding_mask)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:10.561327Z","iopub.execute_input":"2024-08-31T07:32:10.562172Z","iopub.status.idle":"2024-08-31T07:32:10.572014Z","shell.execute_reply.started":"2024-08-31T07:32:10.562139Z","shell.execute_reply":"2024-08-31T07:32:10.571097Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass Transformer(tf.keras.Model):\n    def __init__(self,\n                 dim, enc_layers,\n                 dec_layers, heads,\n                 dff,\n                 vocab_size,\n                 dropout_rate=0.1,\n                 ilen=2048, tlen=2048,**kwargs):\n        super(Transformer, self).__init__()\n        self.name = \"\"\n        self.dim = dim\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n        self.dff = dff\n        self.heads = heads\n        self.vocab_size = vocab_size\n        self.dropout_rate = dropout_rate\n        self.ilen = ilen\n        self.tlen = tlen\n        self.encoder = Encoder(\n            self.dim, self.enc_layers, self.heads,\n            self.dff, self.vocab_size, dropout_rate=self.dropout_rate, length=self.ilen)\n        self.decoder = Decoder(self.dim, self.dec_layers, self.heads, self.dff,self.vocab_size,\n                               dropout_rate=self.dropout_rate, length=self.tlen)\n        self.linear = Dense(self.vocab_size)\n    \n    def get_config(self):\n        config = super(Transformer, self).get_config()\n        config.update({\n            'dim': self.encoder.dim,   # Asumiendo que estos son atributos de Encoder y Decoder\n            'enc_layers': self.enc_layers,\n            'dec_layers': self.dec_layers,\n            'heads': self.heads,\n            'dff': self.dff,\n            'vocab_size': self.vocab_size,\n            'dropout_rate': self.dropout_rate,\n            'ilen': self.ilen,  # Assuming `length` is the length of the encoder\n            'tlen': self.tlen,  # Assuming `length` is the length of the decoder\n        })\n        return config\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n    def build(self,input_shape):\n        super(Transformer,self).build(input_shape)\n    \n    def call(self, inputs, src_padding_mask=None, look_ahead_mask=None, tgt_padding_mask=None, training=None):\n        context, x = inputs\n        enc_out = self.encoder(context, src_padding_mask, training=training)\n        dec_out = self.decoder(x, enc_out,\n                               look_ahead_mask=look_ahead_mask,\n                               tgt_padding_mask=tgt_padding_mask,\n                               training=training)\n        logits = self.linear(dec_out)\n\n        try:\n            del logits.keras_mask\n        except AttributeError:\n            pass\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:11.513983Z","iopub.execute_input":"2024-08-31T07:32:11.514653Z","iopub.status.idle":"2024-08-31T07:32:11.527873Z","shell.execute_reply.started":"2024-08-31T07:32:11.514621Z","shell.execute_reply":"2024-08-31T07:32:11.526803Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"using_tpu=False","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:12.608681Z","iopub.execute_input":"2024-08-31T07:32:12.609061Z","iopub.status.idle":"2024-08-31T07:32:12.613356Z","shell.execute_reply.started":"2024-08-31T07:32:12.609032Z","shell.execute_reply":"2024-08-31T07:32:12.612413Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"dim=512\nenc_layers=4\ndec_layers=4\nheads=8\ndff=2048\ndropout_rate=0.1\nilen=500\ntlen=5000\nif using_tpu:\n    with tpu_strategy.scope():\n        transformer = Transformer(dim,\n                                  enc_layers,\n                                  dec_layers,\n                                  heads,\n                                  dff,\n                                  vocab_size,\n                                  dropout_rate=dropout_rate,\n                                  ilen=ilen,\n                                  tlen=tlen)\nelse:\n    transformer = Transformer(dim,\n                                  enc_layers,\n                                  dec_layers,\n                                  heads,\n                                  dff,\n                                  vocab_size,\n                                  dropout_rate=dropout_rate,\n                                  ilen=ilen,\n                                  tlen=tlen)\n    input_shape = (1, ilen)\n    transformer.build(input_shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:15.295025Z","iopub.execute_input":"2024-08-31T07:32:15.295874Z","iopub.status.idle":"2024-08-31T07:32:15.907783Z","shell.execute_reply.started":"2024-08-31T07:32:15.295826Z","shell.execute_reply":"2024-08-31T07:32:15.907004Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"transformer.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:18.985877Z","iopub.execute_input":"2024-08-31T07:33:18.986831Z","iopub.status.idle":"2024-08-31T07:33:19.003647Z","shell.execute_reply.started":"2024-08-31T07:33:18.986796Z","shell.execute_reply":"2024-08-31T07:33:19.002781Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"input_shape = (1, ilen)\ntransformer.build(input_shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:20.202613Z","iopub.execute_input":"2024-08-31T07:33:20.203281Z","iopub.status.idle":"2024-08-31T07:33:20.207786Z","shell.execute_reply.started":"2024-08-31T07:33:20.203247Z","shell.execute_reply":"2024-08-31T07:33:20.206824Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:19.237269Z","iopub.execute_input":"2024-08-31T07:32:19.237671Z","iopub.status.idle":"2024-08-31T07:32:19.242909Z","shell.execute_reply.started":"2024-08-31T07:32:19.237641Z","shell.execute_reply":"2024-08-31T07:32:19.241975Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def create_masks(inp, tar):\n    # Encoder padding mask\n    enc_padding_mask = create_padding_mask(inp)\n\n    dec_padding_mask = create_padding_mask(inp)\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    dec_target_padding_mask = create_padding_mask(tar)\n    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n\n    return enc_padding_mask, combined_mask, dec_padding_mask","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:32:21.048988Z","iopub.execute_input":"2024-08-31T07:32:21.049376Z","iopub.status.idle":"2024-08-31T07:32:21.054927Z","shell.execute_reply.started":"2024-08-31T07:32:21.049346Z","shell.execute_reply":"2024-08-31T07:32:21.053901Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"\nexample_input = (tf.zeros((1, ilen)),\n                 tf.zeros((1, tlen)))\na,b,c = create_masks(example_input[0],example_input[1])\ntransformer(example_input,a,b,c)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.load_weights(\"wr.weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, d_model, warmup_steps=4000):\n        super().__init__()\n\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n\n        self.warmup_steps = warmup_steps\n\n    def __call__(self, step):\n        step = tf.cast(step, dtype=tf.float32)\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps ** -1.5)\n\n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:27.703108Z","iopub.execute_input":"2024-08-31T07:33:27.703502Z","iopub.status.idle":"2024-08-31T07:33:27.710846Z","shell.execute_reply.started":"2024-08-31T07:33:27.703464Z","shell.execute_reply":"2024-08-31T07:33:27.709848Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"if using_tpu:\n    with tpu_strategy.scope():\n        learning_rate = CustomSchedule(dim,500)\n        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n                                             epsilon=1e-9)\nelse:\n    learning_rate = CustomSchedule(dim,500)\n    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n                                             epsilon=1e-9)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:28.301731Z","iopub.execute_input":"2024-08-31T07:33:28.302162Z","iopub.status.idle":"2024-08-31T07:33:28.310343Z","shell.execute_reply.started":"2024-08-31T07:33:28.302131Z","shell.execute_reply":"2024-08-31T07:33:28.309549Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"ckpt_path = \"./\"\nckpt_prefix = os.path.join(ckpt_path,\"ckpt\")\nckpt = tf.train.Checkpoint(\n    optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:29.705059Z","iopub.execute_input":"2024-08-31T07:33:29.705479Z","iopub.status.idle":"2024-08-31T07:33:29.710784Z","shell.execute_reply.started":"2024-08-31T07:33:29.705448Z","shell.execute_reply":"2024-08-31T07:33:29.709790Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"optimizer.build(transformer.trainable_variables)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.trainable_variables","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:35.859965Z","iopub.execute_input":"2024-08-31T07:33:35.860358Z","iopub.status.idle":"2024-08-31T07:33:35.866643Z","shell.execute_reply.started":"2024-08-31T07:33:35.860329Z","shell.execute_reply":"2024-08-31T07:33:35.865734Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"ckpt_manager = tf.train.CheckpointManager(ckpt, ckpt_path, max_to_keep=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.save(ckpt_prefix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_manager.restore_or_initialize()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.restore(\"ckpt-1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if using_tpu:\n    with tpu_strategy.scope():\n        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\nelse:\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:41.016172Z","iopub.execute_input":"2024-08-31T07:33:41.017123Z","iopub.status.idle":"2024-08-31T07:33:41.022253Z","shell.execute_reply.started":"2024-08-31T07:33:41.017087Z","shell.execute_reply":"2024-08-31T07:33:41.021258Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def masked_loss(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n    #return tf.reduce_mean(loss_)\n\ndef masked_accuracy(label, pred):\n    pred = tf.argmax(pred, axis=2)\n    label = tf.cast(label, pred.dtype)\n    match = label == pred\n\n    mask = label != 0\n\n    match = match & mask\n\n    match = tf.cast(match, dtype=tf.float32)\n    mask = tf.cast(mask, dtype=tf.float32)\n    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:38.463595Z","iopub.execute_input":"2024-08-31T07:33:38.464338Z","iopub.status.idle":"2024-08-31T07:33:38.471424Z","shell.execute_reply.started":"2024-08-31T07:33:38.464309Z","shell.execute_reply":"2024-08-31T07:33:38.470520Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"@tf.function()\ndef train_step(inp,tg,clip_value=1.0):\n    tg_m = tg[:,:-1]\n    tg_f = tg[:,1:]\n    s = tf.shape(tg_m)\n    \n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp,tg_m)\n    with tf.GradientTape() as tape:\n        pred = transformer(\n        inputs=(inp, tg_m),\n        training=True,\n        src_padding_mask=enc_padding_mask,\n        look_ahead_mask=combined_mask,\n        tgt_padding_mask=dec_padding_mask\n        )\n\n        loss = masked_loss(tg_f,pred)\n        grads = tape.gradient(loss,transformer.trainable_variables)\n\n    #grads = [tf.clip_by_value(grad, -clip_value, clip_value) for grad in grads]\n    optimizer.apply_gradients(zip(grads,transformer.trainable_variables))\n    batch_acc = masked_accuracy(tg_f,pred)\n    return loss,batch_acc","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:43.074697Z","iopub.execute_input":"2024-08-31T07:33:43.075073Z","iopub.status.idle":"2024-08-31T07:33:43.083142Z","shell.execute_reply.started":"2024-08-31T07:33:43.075044Z","shell.execute_reply":"2024-08-31T07:33:43.082123Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nfor epoch in range(epochs):\n    print(\"Epoch {}\".format(epoch+1))\n    n = 0\n    l=0\n    ac=0\n    for inp,tg in dataset:\n        if using_tpu:\n            la,acc = tpu_strategy.gather(tpu_strategy.run(train_step,args=(inp,tg)),axis=0)\n        else:\n            la,acc = train_step(inp,tg)\n        l += la\n        ac+=acc\n        n +=1\n        \n        print(\".\",end=\"\")\n    print()\n    print(\"Loss {} \\nAccuracy {}\".format(l/n,ac/n))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:33:44.885057Z","iopub.execute_input":"2024-08-31T07:33:44.885754Z","iopub.status.idle":"2024-08-31T07:54:27.964946Z","shell.execute_reply.started":"2024-08-31T07:33:44.885715Z","shell.execute_reply":"2024-08-31T07:54:27.963499Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch 1\n..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\nLoss nan \nAccuracy 0.046973615884780884\nEpoch 2\n..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\nLoss nan \nAccuracy 0.0\nEpoch 3\n...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[55], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     la,acc \u001b[38;5;241m=\u001b[39m tpu_strategy\u001b[38;5;241m.\u001b[39mgather(tpu_strategy\u001b[38;5;241m.\u001b[39mrun(train_step,args\u001b[38;5;241m=\u001b[39m(inp,tg)),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     la,acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m l \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m la\n\u001b[1;32m     13\u001b[0m ac\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39macc\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"for inp,tg in dataset.take(1):\n    inp_m = inp\n    tg_m = tg[:,:-1]\n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp_m,tg_m)\n    #tpreds = tpu_strategy.run(tpu_transformer_pred,\n    #                          args=((inp_m,tg_m),\n    #                                enc_padding_mask,\n    #                                combined_mask, \n    #                                dec_padding_mask))\n    #tpreds = np.array(tpu_strategy.gather(tpreds, axis=0))\n    pred = transformer((inp_m,tg_m),\n                       src_padding_mask=enc_padding_mask,\n                       look_ahead_mask=combined_mask,\n                       tgt_padding_mask=dec_padding_mask)\n    preds = [int(tf.argmax(p)) for p in pred[0]]\n    print(tokenizer.sequences_to_texts([np.array(inp[0])]))\n    #print(preds)\n    #print(tg[0])\n    print(tokenizer.sequences_to_texts([preds]))\n    print(tokenizer.sequences_to_texts([np.array(tg[0])]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_with_transformer(model,text, max_len=20):\n    text_with_start = f\"{begin_token} {text.lower()} {end_token}\"\n    \n    sequence_input = tokenizer.texts_to_sequences([text_with_start])[0]\n    print(sequence_input)\n    encoder_input = tf.expand_dims(sequence_input,0)\n    \n    decoder_input = [tokenizer.word_index.get(begin_token, 0)]\n    output = tf.expand_dims(decoder_input,0)\n    for step in range(max_len):\n        # Preparar los inputs para el modelo\n        # Crear las máscaras necesarias\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n\n        # Obtener logits del modelo\n        logits = model((encoder_input,output), training=False,\n                             src_padding_mask=enc_padding_mask,\n                             look_ahead_mask=combined_mask,\n                             tgt_padding_mask=dec_padding_mask)\n\n        \n        logits_for_last_token = logits[:, -1, :]  # (batch_size, vocab_size)\n        #print(\"Dimensiones de logits_for_last_token:\", logits_for_last_token.shape)\n\n        predicted_id = tf.cast([tf.argmax(logits_for_last_token,axis=-1)],tf.int32)\n        #print(predicted_id)\n        #print(output)\n        if predicted_id == tokenizer.word_index.get(end_token, 0):\n            return tf.squeeze(output, axis=0)\n\n        output = tf.concat([output, predicted_id], axis=-1)\n\n        print(tokenizer.sequences_to_texts([[tf.squeeze(predicted_id).numpy()]])[0] +\" \",end=\"\")\n        \n    # Convertir los tokens a texto utilizando el tokenizer de salida\n    predicted_sequence = tokenizer.sequences_to_texts([tf.squeeze(output).numpy()])\n        \n    # Mostrar la secuencia de tokens generados para depuración\n    #print(f\"Tokens generados: {decoder_input}\")\n    \n    return predicted_sequence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_with_transformer(transformer,\" chat gpt is smarter than humans \",50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Guardamos el tokenizador y el modelo**","metadata":{}},{"cell_type":"code","source":"!rm tokenizer.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import io\nimport json\n#Guardamos tokenizador\ninp_t_json = tokenizer.to_json()\nwith io.open('tokenizer.json', 'w', encoding='utf-8') as f:\n    f.write(json.dumps(inp_t_json, ensure_ascii=False))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.config.list_physical_devices())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"CPU\"):\n    transformer2 = Transformer(dim,\n                                  enc_layers,\n                                  dec_layers,\n                                  heads,\n                                  dff,\n                                  vocab_size,\n                                  dropout_rate=dropout_rate,\n                                  ilen=ilen,\n                                  tlen=tlen)\n    \n    \n    example_input = (tf.zeros((1, ilen)),\n                     tf.zeros((1, tlen)))\n    a,b,c = create_masks(example_input[0],example_input[1])\n    transformer2(example_input,a,b,c)\n    \n    transformer2.set_weights(transformer.get_weights())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tf.keras.saving.save_model(transformer,\"transformer.h5\")\ntransformer2.save_weights(\"wr.weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer2.load_weights(\"w.weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_with_transformer(transformer2,\" good. what are you doing \",100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.save(ckpt_prefix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = os.listdir(ckpt_path)\nnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(names[-3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(\"checkpoints/\"+names[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(\"checkpoints/\"+names[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model(\"transformer.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}